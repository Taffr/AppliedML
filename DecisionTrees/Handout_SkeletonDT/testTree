// The Decision Tree
digraph {
	0 [label="
id: 0
attribute: size
entropy: 0.9886994082884974
samples: 16
classes: ['s', 'l']
classCount: {'+': 9, '-': 7}"]
	0 -> 0
	1 [label="
id: 1
attribute: shape
entropy: 0.8112781244591328
samples: 8
classes: ['r', 'i']
classCount: {'+': 6, '-': 2}"]
	1 -> 1
	2 [label="
id: 2
attribute: color
entropy: 0.9182958340544896
samples: 6
classes: ['y', 'g']
classCount: {'+': 4, '-': 2}"]
	2 -> 2
	3 [label="
id: 3
label: +
entropy: 0.7219280948873623
samples: 5
classes: []
classCount: {'+': 4, '-': 1}"]
	3 -> 3
	4 [label="
id: 4
label: -
entropy: 0.0
samples: 1
classes: []"]
	4 -> 4
	5 [label="
id: 5
label: +
entropy: 0.0
samples: 2
classes: []"]
	5 -> 5
	6 [label="
id: 6
attribute: color
entropy: 0.9544340029249649
samples: 8
classes: ['y', 'g']
classCount: {'-': 5, '+': 3}"]
	6 -> 6
	7 [label="
id: 7
attribute: shape
entropy: 0.9852281360342516
samples: 7
classes: ['r', 'i']
classCount: {'+': 3, '-': 4}"]
	7 -> 7
	8 [label="
id: 8
label: -
entropy: 0.9182958340544896
samples: 6
classes: []
classCount: {'+': 2, '-': 4}"]
	8 -> 8
	9 [label="
id: 9
label: +
entropy: 0.0
samples: 1
classes: []"]
	9 -> 9
	10 [label="
id: 10
label: -
entropy: 0.0
samples: 1
classes: []"]
	10 -> 10
}
